{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended Thinking - Multi-Model Support\n",
    "\n",
    "## Table of contents\n",
    "- [Setup](#setup)\n",
    "- [Model Configuration](#model-configuration)\n",
    "- [Basic Examples](#basic-examples)\n",
    "- [Multi-Model Comparison](#multi-model-comparison)\n",
    "- [Streaming with Extended Thinking](#streaming-with-extended-thinking)\n",
    "- [Token Management](#token-management)\n",
    "- [Redacted Thinking](#redacted-thinking)\n",
    "- [Agent Integration](#agent-integration)\n",
    "- [Error Handling](#error-handling)\n",
    "\n",
    "This notebook demonstrates Claude's extended thinking feature across multiple models.\n",
    "\n",
    "Extended thinking gives Claude enhanced reasoning capabilities for complex tasks, with transparency into the step-by-step thought process. Available on Claude 3.7 Sonnet and newer models.\n",
    "\n",
    "**Learn more:** [Extended Thinking Documentation](https://docs.claude.com/en/docs/build-with-claude/extended-thinking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "Install dependencies and configure the client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install anthropic --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "import os\n",
    "from typing import Dict, List, Optional\n",
    "\n",
    "# Initialize client\n",
    "client = anthropic.Anthropic(\n",
    "    api_key=os.environ.get(\"ANTHROPIC_API_KEY\")\n",
    ")\n",
    "\n",
    "# Model configuration with extended thinking support\n",
    "MODELS = {\n",
    "    \"sonnet-4.5\": {\n",
    "        \"id\": \"claude-sonnet-4-5\",\n",
    "        \"thinking_support\": True,\n",
    "        \"min_thinking_tokens\": 1024,\n",
    "        \"max_thinking_tokens\": 32000,\n",
    "        \"context_window\": 200000,\n",
    "        \"description\": \"Latest Sonnet with extended thinking\"\n",
    "    },\n",
    "    \"sonnet-3.7\": {\n",
    "        \"id\": \"claude-3-7-sonnet-20250219\",\n",
    "        \"thinking_support\": True,\n",
    "        \"min_thinking_tokens\": 1024,\n",
    "        \"max_thinking_tokens\": 32000,\n",
    "        \"context_window\": 200000,\n",
    "        \"description\": \"Claude 3.7 Sonnet with extended thinking\"\n",
    "    },\n",
    "    \"opus-4\": {\n",
    "        \"id\": \"claude-opus-4-20250514\",\n",
    "        \"thinking_support\": True,\n",
    "        \"min_thinking_tokens\": 1024,\n",
    "        \"max_thinking_tokens\": 32000,\n",
    "        \"context_window\": 200000,\n",
    "        \"description\": \"Opus 4 with extended thinking (if available)\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def print_thinking_response(response, show_full: bool = False):\n",
    "    \"\"\"Pretty print message response with thinking blocks.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"RESPONSE BREAKDOWN\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for i, block in enumerate(response.content, 1):\n",
    "        if block.type == \"thinking\":\n",
    "            print(f\"\\nüß† THINKING BLOCK {i}\")\n",
    "            print(\"-\" * 60)\n",
    "            if show_full:\n",
    "                print(block.thinking)\n",
    "            else:\n",
    "                preview = block.thinking[:300]\n",
    "                print(f\"{preview}...\" if len(block.thinking) > 300 else preview)\n",
    "                print(f\"\\n[Total length: {len(block.thinking)} chars]\")\n",
    "            \n",
    "            if hasattr(block, 'signature') and block.signature:\n",
    "                print(f\"[Signature: {block.signature[:50]}...]\")\n",
    "                \n",
    "        elif block.type == \"redacted_thinking\":\n",
    "            print(f\"\\nüîí REDACTED THINKING BLOCK {i}\")\n",
    "            print(\"-\" * 60)\n",
    "            print(f\"[Encrypted data length: {len(block.data) if hasattr(block, 'data') else 'N/A'}]\")\n",
    "            \n",
    "        elif block.type == \"text\":\n",
    "            print(f\"\\n‚úì FINAL ANSWER {i}\")\n",
    "            print(\"-\" * 60)\n",
    "            print(block.text)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
    "\n",
    "def count_tokens(messages: List[Dict], model: str = \"claude-sonnet-4-5\") -> int:\n",
    "    \"\"\"Count input tokens for messages.\"\"\"\n",
    "    result = client.messages.count_tokens(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return result.input_tokens\n",
    "\n",
    "def get_model_info(model_key: str) -> Dict:\n",
    "    \"\"\"Get model configuration.\"\"\"\n",
    "    if model_key not in MODELS:\n",
    "        raise ValueError(f\"Unknown model: {model_key}. Available: {list(MODELS.keys())}\")\n",
    "    return MODELS[model_key]\n",
    "\n",
    "print(\"‚úì Extended thinking utilities loaded\")\n",
    "print(f\"\\nAvailable models: {list(MODELS.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration\n",
    "\n",
    "Check which models support extended thinking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_model_capabilities():\n",
    "    \"\"\"Display model capabilities for extended thinking.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"EXTENDED THINKING MODEL CAPABILITIES\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    for key, config in MODELS.items():\n",
    "        print(f\"Model: {key}\")\n",
    "        print(f\"  ID: {config['id']}\")\n",
    "        print(f\"  Description: {config['description']}\")\n",
    "        print(f\"  Extended Thinking: {'‚úì Supported' if config['thinking_support'] else '‚úó Not supported'}\")\n",
    "        \n",
    "        if config['thinking_support']:\n",
    "            print(f\"  Token Range: {config['min_thinking_tokens']:,} - {config['max_thinking_tokens']:,}\")\n",
    "            print(f\"  Context Window: {config['context_window']:,}\")\n",
    "        \n",
    "        print()\n",
    "\n",
    "show_model_capabilities()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Examples\n",
    "\n",
    "### Simple Problem Solving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_thinking_example(model_key: str = \"sonnet-4.5\"):\n",
    "    \"\"\"Basic extended thinking example.\"\"\"\n",
    "    model = get_model_info(model_key)\n",
    "    \n",
    "    if not model['thinking_support']:\n",
    "        print(f\"‚ùå Model {model_key} does not support extended thinking\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Using model: {model['id']}\\n\")\n",
    "    \n",
    "    response = client.messages.create(\n",
    "        model=model['id'],\n",
    "        max_tokens=4000,\n",
    "        thinking={\n",
    "            \"type\": \"enabled\",\n",
    "            \"budget_tokens\": 2000\n",
    "        },\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Solve: Three people check into a hotel and pay $30. The manager finds the room costs $25, so gives $5 to a bellboy to return. The bellboy keeps $2 and gives $1 to each person. Each person paid $9 ($27 total), plus the bellboy's $2 = $29. Where's the missing $1?\"\n",
    "        }]\n",
    "    )\n",
    "    \n",
    "    print_thinking_response(response)\n",
    "    return response\n",
    "\n",
    "# Run example\n",
    "basic_thinking_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-Model Comparison\n",
    "\n",
    "Compare how different models approach the same problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(prompt: str, thinking_budget: int = 2000):\n",
    "    \"\"\"Compare extended thinking across models.\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for model_key, config in MODELS.items():\n",
    "        if not config['thinking_support']:\n",
    "            print(f\"\\n‚äò Skipping {model_key} (no thinking support)\")\n",
    "            continue\n",
    "        \n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"TESTING: {model_key} ({config['id']})\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        try:\n",
    "            response = client.messages.create(\n",
    "                model=config['id'],\n",
    "                max_tokens=3000,\n",
    "                thinking={\n",
    "                    \"type\": \"enabled\",\n",
    "                    \"budget_tokens\": thinking_budget\n",
    "                },\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "            )\n",
    "            \n",
    "            # Analyze response\n",
    "            thinking_blocks = [b for b in response.content if b.type == \"thinking\"]\n",
    "            text_blocks = [b for b in response.content if b.type == \"text\"]\n",
    "            \n",
    "            results[model_key] = {\n",
    "                \"response\": response,\n",
    "                \"thinking_chars\": sum(len(b.thinking) for b in thinking_blocks),\n",
    "                \"answer_chars\": sum(len(b.text) for b in text_blocks),\n",
    "                \"num_thinking_blocks\": len(thinking_blocks)\n",
    "            }\n",
    "            \n",
    "            print(f\"\\nüìä Stats:\")\n",
    "            print(f\"  Thinking blocks: {results[model_key]['num_thinking_blocks']}\")\n",
    "            print(f\"  Thinking chars: {results[model_key]['thinking_chars']:,}\")\n",
    "            print(f\"  Answer chars: {results[model_key]['answer_chars']:,}\")\n",
    "            \n",
    "            print_thinking_response(response)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Error with {model_key}: {e}\")\n",
    "            results[model_key] = {\"error\": str(e)}\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example comparison\n",
    "comparison_prompt = \"\"\"Calculate the compound annual growth rate (CAGR) for an investment that:\n",
    "- Started at $10,000\n",
    "- Ended at $25,000\n",
    "- Held for 7 years\n",
    "\n",
    "Show your reasoning step by step.\"\"\"\n",
    "\n",
    "# Uncomment to run comparison\n",
    "# results = compare_models(comparison_prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming with Extended Thinking\n",
    "\n",
    "Handle streaming responses with thinking blocks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def streaming_thinking(prompt: str, model_key: str = \"sonnet-4.5\"):\n",
    "    \"\"\"Stream extended thinking response.\"\"\"\n",
    "    model = get_model_info(model_key)\n",
    "    \n",
    "    print(f\"Streaming from {model['id']}...\\n\")\n",
    "    \n",
    "    with client.messages.stream(\n",
    "        model=model['id'],\n",
    "        max_tokens=4000,\n",
    "        thinking={\n",
    "            \"type\": \"enabled\",\n",
    "            \"budget_tokens\": 2000\n",
    "        },\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    ) as stream:\n",
    "        current_block = None\n",
    "        current_content = \"\"\n",
    "        \n",
    "        for event in stream:\n",
    "            if event.type == \"content_block_start\":\n",
    "                current_block = event.content_block.type\n",
    "                if current_block == \"thinking\":\n",
    "                    print(\"\\nüß† THINKING:\")\n",
    "                    print(\"-\" * 60)\n",
    "                elif current_block == \"text\":\n",
    "                    print(\"\\n‚úì ANSWER:\")\n",
    "                    print(\"-\" * 60)\n",
    "                current_content = \"\"\n",
    "                \n",
    "            elif event.type == \"content_block_delta\":\n",
    "                if event.delta.type == \"thinking_delta\":\n",
    "                    print(event.delta.thinking, end=\"\", flush=True)\n",
    "                    current_content += event.delta.thinking\n",
    "                elif event.delta.type == \"text_delta\":\n",
    "                    print(event.delta.text, end=\"\", flush=True)\n",
    "                    current_content += event.delta.text\n",
    "                    \n",
    "            elif event.type == \"content_block_stop\":\n",
    "                if current_block == \"thinking\":\n",
    "                    print(f\"\\n[{len(current_content)} chars]\")\n",
    "                print()\n",
    "                current_block = None\n",
    "                \n",
    "            elif event.type == \"message_stop\":\n",
    "                print(\"\\n\" + \"=\"*60)\n",
    "                print(\"Stream complete\")\n",
    "\n",
    "# Example\n",
    "# streaming_thinking(\"Explain the Monte Carlo method for portfolio risk analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Management\n",
    "\n",
    "Understand token usage with extended thinking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_token_usage(prompt: str, thinking_budgets: List[int] = None):\n",
    "    \"\"\"Analyze token usage across different thinking budgets.\"\"\"\n",
    "    if thinking_budgets is None:\n",
    "        thinking_budgets = [1024, 2000, 4000, 8000]\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    base_tokens = count_tokens(messages)\n",
    "    \n",
    "    print(f\"\\nüìä TOKEN ANALYSIS\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    print(f\"Base input tokens: {base_tokens:,}\\n\")\n",
    "    \n",
    "    model = get_model_info(\"sonnet-4.5\")\n",
    "    context_window = model['context_window']\n",
    "    \n",
    "    for budget in thinking_budgets:\n",
    "        output_buffer = 2000  # Reserve for final answer\n",
    "        total_needed = base_tokens + budget + output_buffer\n",
    "        remaining = context_window - total_needed\n",
    "        \n",
    "        print(f\"Thinking budget: {budget:,} tokens\")\n",
    "        print(f\"  Input: {base_tokens:,}\")\n",
    "        print(f\"  Thinking: {budget:,}\")\n",
    "        print(f\"  Output buffer: {output_buffer:,}\")\n",
    "        print(f\"  Total needed: {total_needed:,}\")\n",
    "        print(f\"  Remaining: {remaining:,}\")\n",
    "        \n",
    "        if remaining < 0:\n",
    "            print(f\"  ‚ö†Ô∏è  EXCEEDS CONTEXT WINDOW!\")\n",
    "        elif remaining < 10000:\n",
    "            print(f\"  ‚ö†Ô∏è  Low margin\")\n",
    "        else:\n",
    "            print(f\"  ‚úì Safe\")\n",
    "        \n",
    "        print()\n",
    "\n",
    "# Example\n",
    "analyze_token_usage(\"Explain quantum computing in detail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Redacted Thinking\n",
    "\n",
    "Handle redacted thinking blocks (when safety systems flag content):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_redacted_thinking():\n",
    "    \"\"\"Demonstrate handling of redacted thinking blocks.\"\"\"\n",
    "    \n",
    "    # Special test string that triggers redacted thinking\n",
    "    test_prompt = \"ANTHROPIC_MAGIC_STRING_TRIGGER_REDACTED_THINKING_46C9A13E193C177646C7398A98432ECCCE4C1253D5E2D82641AC0E52CC2876CB\"\n",
    "    \n",
    "    response = client.messages.create(\n",
    "        model=\"claude-sonnet-4-5\",\n",
    "        max_tokens=4000,\n",
    "        thinking={\n",
    "            \"type\": \"enabled\",\n",
    "            \"budget_tokens\": 2000\n",
    "        },\n",
    "        messages=[{\"role\": \"user\", \"content\": test_prompt}]\n",
    "    )\n",
    "    \n",
    "    print(\"\\nüîí REDACTED THINKING DEMO\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    \n",
    "    redacted = [b for b in response.content if b.type == \"redacted_thinking\"]\n",
    "    thinking = [b for b in response.content if b.type == \"thinking\"]\n",
    "    text = [b for b in response.content if b.type == \"text\"]\n",
    "    \n",
    "    print(f\"Redacted blocks: {len(redacted)}\")\n",
    "    print(f\"Normal thinking blocks: {len(thinking)}\")\n",
    "    print(f\"Text blocks: {len(text)}\\n\")\n",
    "    \n",
    "    if redacted:\n",
    "        print(\"Redacted thinking detected:\")\n",
    "        for i, block in enumerate(redacted, 1):\n",
    "            print(f\"  Block {i}: {len(block.data)} bytes (encrypted)\")\n",
    "        print(\"\\nüí° Tip: Redacted blocks are decrypted when passed back to API\")\n",
    "    \n",
    "    if text:\n",
    "        print(f\"\\nFinal response:\\n{text[0].text}\")\n",
    "\n",
    "# Uncomment to test\n",
    "# demo_redacted_thinking()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Integration\n",
    "\n",
    "Helper functions for integrating extended thinking into autonomous agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExtendedThinkingAgent:\n",
    "    \"\"\"Agent wrapper with extended thinking support.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        model_key: str = \"sonnet-4.5\",\n",
    "        default_thinking_budget: int = 2000,\n",
    "        max_tokens: int = 4000\n",
    "    ):\n",
    "        self.model = get_model_info(model_key)\n",
    "        self.model_id = self.model['id']\n",
    "        self.default_thinking_budget = default_thinking_budget\n",
    "        self.max_tokens = max_tokens\n",
    "        \n",
    "        if not self.model['thinking_support']:\n",
    "            raise ValueError(f\"Model {model_key} does not support extended thinking\")\n",
    "    \n",
    "    def think(self, prompt: str, thinking_budget: Optional[int] = None) -> Dict:\n",
    "        \"\"\"Execute thinking task and return structured result.\"\"\"\n",
    "        budget = thinking_budget or self.default_thinking_budget\n",
    "        \n",
    "        response = client.messages.create(\n",
    "            model=self.model_id,\n",
    "            max_tokens=self.max_tokens,\n",
    "            thinking={\n",
    "                \"type\": \"enabled\",\n",
    "                \"budget_tokens\": budget\n",
    "            },\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "        )\n",
    "        \n",
    "        # Parse response\n",
    "        thinking_blocks = [b for b in response.content if b.type == \"thinking\"]\n",
    "        text_blocks = [b for b in response.content if b.type == \"text\"]\n",
    "        \n",
    "        return {\n",
    "            \"thinking\": [b.thinking for b in thinking_blocks],\n",
    "            \"answer\": \" \".join(b.text for b in text_blocks),\n",
    "            \"raw_response\": response,\n",
    "            \"thinking_chars\": sum(len(b.thinking) for b in thinking_blocks),\n",
    "            \"answer_chars\": sum(len(b.text) for b in text_blocks)\n",
    "        }\n",
    "    \n",
    "    def multi_step_reasoning(self, steps: List[str]) -> List[Dict]:\n",
    "        \"\"\"Execute multi-step reasoning task.\"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for i, step in enumerate(steps, 1):\n",
    "            print(f\"\\nüîÑ Step {i}/{len(steps)}\")\n",
    "            print(\"-\" * 60)\n",
    "            result = self.think(step)\n",
    "            results.append(result)\n",
    "            print(f\"Thinking: {result['thinking_chars']} chars\")\n",
    "            print(f\"Answer: {result['answer'][:200]}...\")\n",
    "        \n",
    "        return results\n",
    "\n",
    "# Example usage\n",
    "agent = ExtendedThinkingAgent(model_key=\"sonnet-4.5\")\n",
    "\n",
    "# Single task\n",
    "result = agent.think(\"Calculate IRR for: Initial: -$1M, Year 1: $300K, Year 2: $400K, Year 3: $500K\")\n",
    "print(f\"\\n‚úì Answer: {result['answer']}\")\n",
    "\n",
    "# Multi-step\n",
    "# steps = [\n",
    "#     \"Analyze the pros and cons of waterfall vs. deal-by-deal carry\",\n",
    "#     \"Calculate scenarios for a $100M fund with 20% carry\",\n",
    "#     \"Recommend optimal structure for 10-year fund lifecycle\"\n",
    "# ]\n",
    "# results = agent.multi_step_reasoning(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling\n",
    "\n",
    "Common errors and how to handle them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_error_handling():\n",
    "    \"\"\"Show common errors and solutions.\"\"\"\n",
    "    \n",
    "    print(\"\\n‚ö†Ô∏è  COMMON ERRORS AND SOLUTIONS\")\n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "    # Error 1: Thinking budget too small\n",
    "    print(\"1Ô∏è‚É£ Thinking budget too small (< 1024 tokens)\\n\")\n",
    "    try:\n",
    "        client.messages.create(\n",
    "            model=\"claude-sonnet-4-5\",\n",
    "            max_tokens=1000,\n",
    "            thinking={\"type\": \"enabled\", \"budget_tokens\": 500},\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Test\"}]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        print(\"‚úì Solution: Use minimum 1024 tokens\\n\")\n",
    "    \n",
    "    # Error 2: Incompatible parameters\n",
    "    print(\"2Ô∏è‚É£ Using temperature with thinking\\n\")\n",
    "    try:\n",
    "        client.messages.create(\n",
    "            model=\"claude-sonnet-4-5\",\n",
    "            max_tokens=1000,\n",
    "            temperature=0.7,  # Not allowed with thinking\n",
    "            thinking={\"type\": \"enabled\", \"budget_tokens\": 2000},\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Test\"}]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        print(\"‚úì Solution: Remove temperature/top_p/top_k parameters\\n\")\n",
    "    \n",
    "    # Error 3: Context window exceeded\n",
    "    print(\"3Ô∏è‚É£ Context window overflow\\n\")\n",
    "    print(\"‚ùå Can happen when: input + thinking_budget + max_tokens > 200k\")\n",
    "    print(\"‚úì Solutions:\")\n",
    "    print(\"  - Reduce thinking budget\")\n",
    "    print(\"  - Reduce max_tokens\")\n",
    "    print(\"  - Shorten input prompt\")\n",
    "    print(\"  - Use progressive summarization\\n\")\n",
    "    \n",
    "    print(\"=\"*80)\n",
    "\n",
    "demonstrate_error_handling()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Takeaways\n",
    "\n",
    "### When to Use Extended Thinking\n",
    "- Complex mathematical calculations\n",
    "- Multi-step reasoning tasks\n",
    "- Code analysis and debugging\n",
    "- Strategic planning\n",
    "- Financial modeling\n",
    "\n",
    "### Best Practices\n",
    "1. Start with minimum budget (1024) and increase as needed\n",
    "2. Monitor token usage to stay within context window\n",
    "3. Handle redacted thinking blocks gracefully\n",
    "4. Stream for long-running tasks\n",
    "5. Don't use with temperature/top_p/top_k\n",
    "\n",
    "### Cost Considerations\n",
    "- Extended thinking tokens count as output tokens\n",
    "- They contribute to rate limits\n",
    "- Budget appropriately for production use\n",
    "\n",
    "### Resources\n",
    "- [Extended Thinking Docs](https://docs.claude.com/en/docs/build-with-claude/extended-thinking)\n",
    "- [API Reference](https://docs.anthropic.com/en/api/messages)\n",
    "- [Pricing](https://www.anthropic.com/pricing)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
