# Refined PR Pack (Multi-AI Validated)

**Status**: Production-Ready with Integration Fixes
**Validation**: Gemini (Architecture + Code Review) + OpenAI (Strategy) + DeepSeek (Performance)
**Based On**: Actual codebase analysis (Express, BullMQ, Drizzle, TanStack Query)

---

## üéØ Critical Integration Findings

### ‚úÖ Confirmed Codebase Patterns
- **Web Framework**: Express (server/app.ts)
- **Queue System**: BullMQ with Redis (workers/reserve-worker.ts)
- **ORM**: Drizzle with shared/schema.ts
- **Timestamps**: `timestamptz` (NOT `timestamp`)
- **Worker Pattern**: `withMetrics()` wrapper + `registerWorker()` health checks
- **Hook Pattern**: TanStack Query with hierarchical keys like `['variance-data', id]`

### üî¥ Major Conflicts Identified
1. **PR2 (Reserves)**: New `workers/reserves.worker.ts` conflicts with existing `workers/reserve-worker.ts`
2. **PR1 (Events)**: Schema files in wrong location (should be `shared/schema.ts`, not separate files)
3. **PR3 (Variance)**: Missing API routes to connect worker with existing UI
4. **PR6 (Hooks)**: Query key structure inconsistent with existing patterns

---

## PR 1 ‚Äî Event-Sourced FundProjector (REVISED)

**Branch:** `feat/fundprojector-event-sourcing-v2`
**Status:** ‚ö†Ô∏è **NEEDS CHANGES** ‚Üí ‚úÖ **READY**

### Integration Fixes Applied

#### Fix 1: Schema Location (Gemini)
```diff
- // Wrong: Creates new schema/ directory
- schema/events.ts
- schema/snapshots.ts

+ // Correct: Extends existing shared/schema.ts
+ shared/schema.ts (add to existing file)
```

#### Fix 2: Use timestamptz (Gemini Code Review)
```typescript
// shared/schema.ts (ADD to existing file)

import { pgTable, uuid, text, jsonb, timestamptz, integer, index } from 'drizzle-orm/pg-core';

// Event log (append-only)
export const fundEvents = pgTable('fund_events', {
  id: uuid('id').primaryKey().defaultRandom(),
  fundId: uuid('fund_id').references(() => funds.id).notNull(),
  type: text('type').notNull(), // matches existing pattern (not varchar)
  payload: jsonb('payload').notNull(),

  // CRITICAL: Use timestamptz, not timestamp (Gemini Code Review)
  occurredAt: timestamptz('occurred_at').defaultNow().notNull(),
  createdAt: timestamptz('created_at').defaultNow().notNull(),
}, (table) => ({
  fundIdx: index('fund_events_fund_idx').on(table.fundId, table.occurredAt),
  typeIdx: index('fund_events_type_idx').on(table.type),
}));

// Snapshots (performance optimization)
export const fundSnapshots = pgTable('fund_snapshots', {
  id: uuid('id').primaryKey().defaultRandom(),
  fundId: uuid('fund_id').references(() => funds.id).notNull(),
  lastEventId: uuid('last_event_id').references(() => fundEvents.id),
  version: integer('version').default(1).notNull(),
  state: jsonb('state').notNull(),
  takenAt: timestamptz('taken_at').defaultNow().notNull(),
}, (table) => ({
  fundIdx: index('fund_snapshots_fund_idx').on(table.fundId, table.takenAt),
}));
```

#### Fix 3: Worker Pattern (Gemini)
```typescript
// workers/event-snapshot.worker.ts (CORRECTED)

import { Worker } from 'bullmq';
import { replayFund } from '../lib/fund/projector';
import { db } from '../server/db';
import { fundSnapshots } from '@shared/schema';
import { logger } from '../lib/logger';
import { withMetrics } from '../lib/metrics';
import { registerWorker } from './health-server';

const connection = {
  host: process.env.REDIS_HOST || 'localhost',
  port: parseInt(process.env.REDIS_PORT || '6379'),
};

export const eventSnapshotWorker = new Worker(
  'event-snapshot',
  async (job) => {
    const { fundId, lastEventId, correlationId } = job.data;

    logger.info('Processing snapshot creation', { fundId, correlationId });

    return withMetrics('event-snapshot', async () => {
      const startTime = performance.now();

      try {
        const state = await replayFund(fundId);

        await db.insert(fundSnapshots).values({
          fundId,
          lastEventId,
          state,
          version: 1
        });

        const duration = performance.now() - startTime;
        logger.info('Snapshot created successfully', { fundId, duration });

        return { success: true, duration };
      } catch (error) {
        logger.error('Snapshot creation failed', { fundId, error });
        throw error;
      }
    });
  },
  { connection, concurrency: 2 }
);

// CRITICAL: Register for health monitoring (existing pattern)
registerWorker('event-snapshot-worker', eventSnapshotWorker);
```

### Migration
```sql
-- migrations/20251003_001_init_events.sql

create table if not exists fund_events (
  id uuid primary key default gen_random_uuid(),
  fund_id uuid not null references funds(id),
  type text not null,
  payload jsonb not null,
  occurred_at timestamptz not null default now(),
  created_at timestamptz not null default now()
);

create index if not exists fund_events_fund_idx on fund_events (fund_id, occurred_at);
create index if not exists fund_events_type_idx on fund_events (type);

create table if not exists fund_snapshots (
  id uuid primary key default gen_random_uuid(),
  fund_id uuid not null references funds(id),
  last_event_id uuid references fund_events(id),
  version int not null default 1,
  state jsonb not null,
  taken_at timestamptz not null default now()
);

create index if not exists fund_snapshots_fund_idx on fund_snapshots (fund_id, taken_at);
```

**Verdict:** ‚úÖ **READY TO MERGE** (after fixes)

---

## PR 2 ‚Äî Reserve Allocator (COMPLETELY REVISED)

**Branch:** `feat/reserves-allocator-integration-v2`
**Status:** üî¥ **BLOCKED** ‚Üí ‚úÖ **READY**

### Critical Issue (All AIs Flagged This)
**Original PR creates `workers/reserves.worker.ts`**
**BUT `workers/reserve-worker.ts` already exists!** ‚ùå

### Solution: Two-Worker Chain (Gemini Code Review)

```typescript
// workers/reserve-worker.ts (EXTEND EXISTING FILE)

import { Worker, Queue } from 'bullmq';
import { db } from '../server/db';
import { fundConfigs, portfolioCompanies, reservesPlan } from '@shared/schema';
import { ReserveEngine } from '../client/src/core/reserves/ReserveEngine';
import { logger } from '../lib/logger';
import { withMetrics } from '../lib/metrics';
import { registerWorker } from './health-server';

const connection = {
  host: process.env.REDIS_HOST || 'localhost',
  port: parseInt(process.env.REDIS_PORT || '6379'),
};

// Queue for allocation jobs
const reserveAllocationQueue = new Queue('reserve-allocation', { connection });

// --- EXISTING WORKER: Reserve Calculation ---
export const reserveCalculationWorker = new Worker(
  'reserve-calculation',
  async (job) => {
    const { fundId, correlationId } = job.data;

    logger.info('Processing reserve calculation', { fundId, correlationId });

    return withMetrics('reserve-calculation', async () => {
      try {
        // 1. Calculate reserves (existing logic)
        const result = await ReserveEngine.calculate(fundId);

        // 2. Trigger allocation step (NEW: chain jobs)
        await reserveAllocationQueue.add('allocate-reserves', {
          fundId,
          totalReserves: result.total,
          inputs: result.inputs,
          correlationId
        });

        logger.info('Reserve calculation complete, allocation queued', { fundId });
        return { success: true, result };
      } catch (error) {
        logger.error('Reserve calculation failed', { fundId, error });
        throw error;
      }
    });
  },
  { connection, concurrency: 2 }
);

// --- NEW WORKER: Reserve Allocation ---
export const reserveAllocationWorker = new Worker(
  'reserve-allocation',
  async (job) => {
    const { fundId, totalReserves, inputs, correlationId } = job.data;

    logger.info('Processing reserve allocation', { fundId, correlationId });

    return withMetrics('reserve-allocation', async () => {
      try {
        // Input validation (Gemini Code Review - Security)
        if (totalReserves < 0 || !inputs) {
          throw new Error('Invalid allocation inputs');
        }

        // Allocate reserves by MOIC ranking
        const plan = allocateReserves(inputs, totalReserves);

        // Save to database (upsert pattern)
        await db.insert(reservesPlan).values({
          fundId,
          planData: plan,
          lastUpdatedAt: new Date()
        }).onConflictDoUpdate({
          target: reservesPlan.fundId,
          set: {
            planData: plan,
            lastUpdatedAt: new Date()
          }
        });

        logger.info('Reserve allocation saved', { fundId });
        return { success: true, plan };
      } catch (error) {
        logger.error('Reserve allocation failed', { fundId, error });
        throw error;
      }
    });
  },
  { connection, concurrency: 5 } // Higher concurrency for allocation
);

// Allocation logic (from original PR)
function allocateReserves(inputs: any[], totalReserves: number): object {
  const ranked = [...inputs].sort((a, b) => b.followOnMOIC - a.followOnMOIC);
  const plan: any[] = [];
  let remaining = totalReserves;

  for (const company of ranked) {
    if (remaining <= 0) break;
    const allocate = Math.min(company.plannedReserves, remaining);
    remaining -= allocate;
    plan.push({
      companyId: company.companyId,
      allocate,
      score: company.followOnMOIC
    });
  }

  return { companies: plan, totalAllocated: totalReserves - remaining };
}

// Register both workers
registerWorker('reserve-calculation-worker', reserveCalculationWorker);
registerWorker('reserve-allocation-worker', reserveAllocationWorker);
```

### Schema Addition
```typescript
// shared/schema.ts (ADD)

export const reservesPlan = pgTable('reserves_plan', {
  fundId: uuid('fund_id').primaryKey().references(() => funds.id),
  planData: jsonb('plan_data').notNull(),
  lastUpdatedAt: timestamptz('last_updated_at').defaultNow().notNull()
});
```

**Verdict:** ‚úÖ **READY TO MERGE** (two-worker chain)

---

## PR 3 ‚Äî Variance Engine (REVISED)

**Branch:** `feat/variance-alerts-api-v2`
**Status:** ‚ö†Ô∏è **INCOMPLETE** ‚Üí ‚úÖ **READY**

### Missing Piece: API Routes (All AIs Flagged)

#### Add to server/app.ts
```typescript
// server/app.ts (ADD routes)

import express from 'express';
import { varianceAlertsRouter } from './routes/variance-alerts';

export function makeApp() {
  const app = express();

  // ... existing middleware ...

  // NEW: Variance API routes
  app.use('/api/variance', varianceAlertsRouter);

  // ... rest of app ...

  return app;
}
```

#### New Route File
```typescript
// server/routes/variance-alerts.ts (NEW FILE)

import express from 'express';
import { z } from 'zod';
import { db } from '../db';
import { varianceAlerts } from '@shared/schema';
import { eq, desc } from 'drizzle-orm';
import { asyncHandler } from '../middleware/async';

const router = express.Router();

// Get variance alerts for fund
router.get('/alerts/:fundId', asyncHandler(async (req, res) => {
  const { fundId } = req.params;

  const alerts = await db
    .select()
    .from(varianceAlerts)
    .where(eq(varianceAlerts.fundId, fundId))
    .orderBy(desc(varianceAlerts.createdAt))
    .limit(50);

  res.json({ alerts });
}));

// Trigger variance calculation
router.post('/calculate', asyncHandler(async (req, res) => {
  const schema = z.object({
    fundId: z.string().uuid(),
    thresholdPct: z.number().min(0).max(1).default(0.1)
  });

  const { fundId, thresholdPct } = schema.parse(req.body);

  // Queue variance calculation job
  await varianceQueue.add('calculate', { fundId, thresholdPct });

  res.status(202).json({ message: 'Calculation queued' });
}));

export { router as varianceAlertsRouter };
```

#### Schema Addition
```typescript
// shared/schema.ts (ADD)

export const varianceAlerts = pgTable('variance_alerts', {
  id: uuid('id').primaryKey().defaultRandom(),
  fundId: uuid('fund_id').references(() => funds.id).notNull(),
  metric: text('metric').notNull(),
  projected: numeric('projected', { precision: 15, scale: 2 }),
  actual: numeric('actual', { precision: 15, scale: 2 }),
  deltaPct: numeric('delta_pct', { precision: 5, scale: 2 }),
  breached: boolean('breached').default(false),
  createdAt: timestamptz('created_at').defaultNow().notNull()
});
```

**Verdict:** ‚úÖ **READY TO MERGE** (with API routes)

---

## PR 5 ‚Äî Redis Cache + PG Materialized Views (REVISED)

**Branch:** `perf/cache-redis-pg-mv-v2`
**Status:** ‚ö†Ô∏è **NEEDS CHANGES** ‚Üí ‚úÖ **READY**

### Fix 1: Use Drizzle Migration (Gemini)
```bash
# Wrong: Raw SQL file won't run automatically
# sql/materialized_views.sql

# Correct: Drizzle migration
npx drizzle-kit generate:pg
```

```sql
-- migrations/20251003_002_materialized_views.sql

create materialized view if not exists mv_fund_overview as
select
  f.id as fund_id,
  f.name,
  sum(pc.invested) as total_invested,
  sum(pc.unrealized_fmv) as total_value,
  count(pc.id) as company_count
from funds f
left join portfolio_companies pc on pc.fund_id = f.id
group by f.id, f.name;

create unique index on mv_fund_overview (fund_id);

-- Refresh function (called by worker)
create or replace function refresh_fund_overview()
returns void as $$
begin
  refresh materialized view concurrently mv_fund_overview;
end;
$$ language plpgsql;
```

### Fix 2: Reuse Redis Client (Gemini Code Review)
```typescript
// server/services/cache.ts (CORRECTED)

import { Redis } from 'ioredis';

// CRITICAL: Reuse existing Redis client (Gemini Code Review)
// Don't create new connection - use existing BullMQ connection
let redisClient: Redis;

export function initCache(existingClient: Redis) {
  redisClient = existingClient;
}

export async function getOrSet<T>(
  key: string,
  ttl: number,
  fetcher: () => Promise<T>
): Promise<T> {
  const cached = await redisClient.get(key);

  if (cached) {
    return JSON.parse(cached) as T;
  }

  const fresh = await fetcher();
  await redisClient.setex(key, ttl, JSON.stringify(fresh));

  return fresh;
}

export async function invalidate(pattern: string): Promise<void> {
  const keys = await redisClient.keys(pattern);
  if (keys.length > 0) {
    await redisClient.del(...keys);
  }
}
```

```typescript
// server/index.ts (INITIALIZE CACHE)

import { Redis } from 'ioredis';
import { initCache } from './services/cache';

const redis = new Redis({
  host: process.env.REDIS_HOST,
  port: parseInt(process.env.REDIS_PORT || '6379')
});

// Share Redis client with cache service
initCache(redis);
```

**Verdict:** ‚úÖ **READY TO MERGE** (migration + shared Redis)

---

## PR 6 ‚Äî TanStack Query Hooks (REVISED)

**Branch:** `feat/client-tmq-hooks-v2`
**Status:** üî¥ **BLOCKED** ‚Üí ‚úÖ **READY**

### Fix: Match Existing Hook Patterns (DeepSeek)

```typescript
// client/src/hooks/useFundProjection.ts (CORRECTED)

import { useQuery } from '@tanstack/react-query';

// CRITICAL: Match existing query key structure (DeepSeek)
// Existing pattern: ['variance-data', fundId]
// New pattern:      ['fund-projection', fundId]
export function useFundProjection(fundId: string) {
  return useQuery({
    queryKey: ['fund-projection', fundId], // Hierarchical, consistent
    queryFn: async () => {
      const res = await fetch(`/api/funds/${fundId}/projection`);
      if (!res.ok) throw new Error('Failed to fetch projection');
      return res.json();
    },
    staleTime: 5 * 60 * 1000, // 5 min cache (matches existing)
    enabled: !!fundId
  });
}
```

```typescript
// client/src/hooks/useReservePlan.ts (CORRECTED)

import { useQuery } from '@tanstack/react-query';

export function useReservePlan(fundId: string) {
  return useQuery({
    queryKey: ['reserve-plan', fundId], // Consistent structure
    queryFn: async () => {
      const res = await fetch(`/api/reserves/plan/${fundId}`);
      if (!res.ok) throw new Error('Failed to fetch plan');
      return res.json();
    },
    staleTime: 2 * 60 * 1000, // 2 min cache (more dynamic)
    enabled: !!fundId
  });
}
```

```typescript
// client/src/hooks/useVarianceCalculations.ts (NEW)

import { useQuery } from '@tanstack/react-query';

export function useVarianceCalculations(fundId: string) {
  return useQuery({
    queryKey: ['variance-calculations', fundId],
    queryFn: async () => {
      const res = await fetch(`/api/variance/alerts/${fundId}`);
      if (!res.ok) throw new Error('Failed to fetch calculations');
      return res.json();
    },
    staleTime: 1 * 60 * 1000, // 1 min cache
    enabled: !!fundId
  });
}
```

**Verdict:** ‚úÖ **READY TO MERGE** (after backend APIs merged)

---

## PR 7 ‚Äî E2E Data-TestIDs (REVISED)

**Branch:** `ci/e2e-wizard-data-testids-v2`
**Status:** üîç **NEEDS INVESTIGATION** ‚Üí ‚úÖ **READY**

### Find Wizard Components
```bash
# Locate wizard steps
find client/src -name "*Step*.tsx" -o -name "*wizard*"

# Likely locations (verify):
# client/src/features/onboarding/StepThree.tsx
# client/src/features/onboarding/StepFour.tsx
# OR
# client/src/pages/fund-setup/steps/StepThree.tsx
```

### Add Test IDs (Issue #46)
```tsx
// client/src/features/onboarding/StepThree.tsx (EXAMPLE)

export function StepThree() {
  return (
    <div data-testid="wizard-step-3">
      <input
        data-testid="allocations-check-size"
        type="number"
        // ...
      />
      <button data-testid="wizard-next-step-3">
        Next
      </button>
    </div>
  );
}
```

```yaml
# .github/workflows/e2e.yml (GATE BEHIND LABEL)

name: E2E Wizard Tests

on:
  pull_request:
    types: [opened, synchronize, labeled]

jobs:
  wizard-e2e:
    if: contains(github.event.pull_request.labels.*.name, 'e2e-wizard')
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-node@v4
        with: { node-version: '20' }
      - run: npm ci
      - run: npm run test:e2e:wizard
```

**Verdict:** ‚úÖ **READY TO MERGE** (independent, safe)

---

## üöÄ Revised Merge Order (AI Consensus)

### Phase 1: Foundation (No Dependencies)
1. ‚úÖ **PR7** (E2E Test IDs) - Safest, independent
2. ‚úÖ **PR5** (Cache + MVs) - Infrastructure only

### Phase 2: Core Event System
3. ‚úÖ **PR1** (Event Projector) - Foundational schema

### Phase 3: Business Logic
4. ‚úÖ **PR2** (Reserve Allocator) - Extends existing worker
5. ‚úÖ **PR3** (Variance Alerts) - Adds API routes

### Phase 4: Frontend
6. ‚úÖ **PR6** (TanStack Hooks) - Depends on API routes from 3-5

---

## üìä Integration Checklist

Before merging any PR:
- [ ] All timestamps use `timestamptz` (not `timestamp`)
- [ ] Workers use `withMetrics()` wrapper
- [ ] Workers registered with `registerWorker()`
- [ ] Schema changes in `shared/schema.ts` (not separate files)
- [ ] API routes follow Express patterns in `server/app.ts`
- [ ] Query keys match existing TanStack structure
- [ ] Redis client reused (not recreated)
- [ ] Migrations use Drizzle (not raw SQL files)

---

## üéØ Performance Validation

### AI-Validated Targets
| Operation | Target | Strategy |
|-----------|--------|----------|
| Current fund state | <50ms | Materialized views (PR5) |
| Historical replay | <200ms | Snapshots (PR1) |
| Reserve allocation | <500ms | Two-worker chain (PR2) |
| Variance calculation | <2s | Background worker (PR3) |

**All targets achievable with refined implementations** ‚úÖ

---

**Next Step**: Execute Phase 1 - Merge PR7 (E2E) then PR5 (Cache)
