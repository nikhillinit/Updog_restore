# üèóÔ∏è Comprehensive 6-Month Restructure Strategy
## VC Fund Management Platform: Current ‚Üí Production Architecture

**Version:** 1.0
**Created:** October 2, 2025
**Author:** Multi-AI Collaboration (OpenAI GPT-4 + DeepSeek + Claude Sonnet)
**Stakeholder Demo:** Tomorrow

---

## üìã Executive Summary

This strategy transforms a functional MVP with scattered routes and mock data into a production-ready VC fund management platform with:
- **5-item IA** (Overview/Portfolio/Model/Operate/Report)
- **Centralized KPI selectors** (single source of truth)
- **Deterministic reserve engine** (binary search algorithm)
- **Unified modeling wizard** (7-step XState machine)
- **Automated LP reporting** (template-based)

**Key Innovation:** "Strangler Fig" migration pattern enables continuous demo-ability while systematically replacing legacy architecture.

**Timeline:** 6 sprints √ó 2 weeks = 12 weeks (3 months core development)
**Resource:** Solo developer (35 hrs/week) + AI agents
**Budget:** ~420 development hours + infrastructure costs

---

## üéØ Strategic Approach: The "Strangler Fig" Pattern

### Concept
Like the strangler fig tree that grows around and eventually replaces its host, we'll:

1. **Build new system around old** - New IA wraps existing functionality
2. **Progressively migrate features** - Route by route, component by component
3. **Coexistence period** - Both systems run simultaneously behind feature flags
4. **Eventually replace old system** - When new system provides full coverage

### Why This Works
- ‚úÖ **Maintains demo-ability** - Always have working product
- ‚úÖ **Reduces risk** - Incremental changes vs "big bang" rewrite
- ‚úÖ **Enables learning** - Adjust strategy based on early sprint feedback
- ‚úÖ **Allows rollback** - Feature flags provide instant safety net

---

## üìÖ Sprint Planning (6 Sprints, 2 Weeks Each)

### Sprint 0: Foundation & Demo Prep (Current Week)
**Goal:** Stakeholder demo readiness + architecture foundation

**Deliverables:**
- ‚úÖ Feature flags for all major sections (`new_ia`, `live_kpi_selectors`, etc.)
- ‚úÖ Route redirect stubs (old ‚Üí new IA)
- ‚úÖ Demo components (ComingSoonPage, CompanyDetail)
- ‚úÖ Background work complete (Selector contract, Reserve API spec, Wizard machine)
- ‚úÖ Demo script highlighting target state vision

**Stories:**
1. [2d] Set up feature flag system with kill switch
2. [1d] Create route redirect architecture
3. [2d] Build demo-ready components (Coming Soon pages)
4. [1d] Prepare stakeholder presentation materials

**Risks & Mitigation:**
- ‚ö†Ô∏è **Risk:** Demo shows incomplete functionality
- ‚úÖ **Mitigation:** Clear communication about phased approach, focus on architecture vision

**Demo Tomorrow Checklist:**
- [ ] New 5-item navigation visible
- [ ] KPI dashboard with hardcoded data + architecture note
- [ ] Company detail page with tabs (cap table contextually placed)
- [ ] Coming Soon pages with feature lists and ETAs
- [ ] PowerPoint slides for Reserve Engine and Modeling Wizard

---

### Sprint 1: Centralized Data Layer & Overview Page
**Goal:** Single source of truth for KPIs + new Overview section

**Duration:** 2 weeks (Nov 4-15, 2025)
**Developer Hours:** 70 hours

**Epic:** Implement Selector Contract Pattern

**Stories:**

1. **Implement KPI Selector Infrastructure** [3d]
   - **AC:**
     - Pure selector functions for all 8 KPIs (Committed, Called, Uncalled, Invested, NAV, DPI, TVPI, IRR)
     - XIRR calculation matches Excel's XIRR function (¬±0.01% tolerance)
     - Selectors compose correctly (e.g., `selectTVPI` uses `selectNAV` + `selectDistributions`)
     - "As of" date parameter works for historical snapshots
   - **Tests:** 40+ unit tests (already written by background agent)
   - **Dependencies:** None (foundation)

2. **Create Data Fetching Abstraction Layer** [2d]
   - **AC:**
     - API client wrapper with retry logic (exponential backoff, max 3 retries)
     - Error handling with typed error responses
     - Loading states managed via TanStack Query
     - Mock data provider toggle via `LIVE_KPI_SELECTORS` flag
   - **API Endpoints:**
     - `GET /api/v1/funds/:fundId/snapshot?asOf=YYYY-MM-DD`
     - Response: `FundData` aggregate (investments, valuations, calls, distributions, fees)

3. **Build Overview Page with KPI Cards** [3d]
   - **AC:**
     - 8 KPI cards in grid layout (responsive: 2 cols mobile, 4 tablet, 8 desktop)
     - "As of" date displayed prominently
     - Loading skeletons during data fetch
     - Error state with retry button
     - Feature flag toggle between mock/live data
   - **Design:** Inter headings, Poppins body, Press On palette

4. **Migrate 2 Critical KPIs to Selector Pattern** [2d]
   - **Priority KPIs:** TVPI and IRR (most complex calculations)
   - **AC:**
     - Replace hardcoded calculations in existing pages
     - Verify outputs match previous values (regression test)
     - Add performance monitoring (calculation time < 100ms)

5. **Add Performance Monitoring for KPI Calculations** [1d]
   - **AC:**
     - Console logs in dev mode showing calculation times
     - Sentry performance tracking in production
     - Alert if any KPI calculation exceeds 500ms

**Measurable Outcomes:**
- ‚úÖ 100% of KPIs centralized in selector functions
- ‚úÖ Overview page fully functional with real or mock data toggle
- ‚úÖ Performance: KPI calculations < 100ms P95

**Definition of Done:**
- [ ] All acceptance criteria met
- [ ] Unit test coverage > 80% for new code
- [ ] Integration tests pass with mock API
- [ ] Performance budget maintained (bundle size +10% max)
- [ ] Documentation: ADR-001 (Selector Contract Pattern)

**Risks:**
- ‚ö†Ô∏è **XIRR calculation complexity** - Newton-Raphson convergence edge cases
- ‚úÖ **Mitigation:** Already implemented and tested by background agent

---

### Sprint 2: Portfolio Hub & Reserve Engine
**Goal:** Unified portfolio view + reserve calculation foundation

**Duration:** 2 weeks (Nov 18-29, 2025)
**Developer Hours:** 70 hours

**Epic:** Consolidate Portfolio Experience + Reserve Engine Backend

**Stories:**

1. **Implement Reserve Engine API** [4d]
   - **AC:**
     - Endpoint: `POST /api/v1/reserve/calculate`
     - Binary search algorithm converges in < 100 iterations
     - Handles edge cases: zero allocations, 100% graduation rates, negative cash flows
     - OpenAPI spec matches background agent's specification
   - **Algorithm:**
     ```
     Given: totalAllocatedCapital, initialCheckSize, stages[], followOnStrategy[]
     Find: N initial deals where initialCapital(N) + followOnCapital(N) = totalAllocatedCapital
     Method: Binary search on N from 0 to totalAllocated/initialCheck
     ```
   - **Performance:** < 50ms P50 latency, < 200ms P99

2. **Create Portfolio Aggregation Component** [3d]
   - **AC:**
     - TanStack Table with virtualization (handles 1000+ rows)
     - Column visibility controls ("Manage Columns" dropdown)
     - Saved filter presets via URL params (`?view=summary|cash|reserves`)
     - Sticky header + first column
     - Row click navigates to `/portfolio/:id`
   - **Design:** Dense rows (40px height), 12px cell padding

3. **Migrate Investment Table Functionality** [2d]
   - **AC:**
     - Old route `/investment-table` redirects to `/portfolio?view=table`
     - All existing filters work in new context
     - Saved filters persist via localStorage
     - Add deprecation banner on old route (1-week notice)

4. **Build Reserve Visualization Components** [2d]
   - **AC:**
     - Bar chart showing initial vs follow-on capital per stage
     - Stage progression waterfall (deals entering ‚Üí graduating ‚Üí exiting)
     - Recharts library integration
     - Responsive design (stacks vertically on mobile)

5. **Data Migration Script for Investment Data** [2d]
   - **AC:**
     - Script: `npm run migrate:investments`
     - Exports legacy data to JSON
     - Transforms to new schema (validates with Zod)
     - Imports to PostgreSQL via Drizzle ORM
     - Dry-run mode for testing
     - Rollback capability

**Measurable Outcomes:**
- ‚úÖ Reserve engine API functional with real calculations
- ‚úÖ Portfolio hub consolidates `/investments` + `/investment-table`
- ‚úÖ Data migration script tested on staging

**Definition of Done:**
- [ ] All acceptance criteria met
- [ ] API load tested: 100 req/min without errors
- [ ] E2E test: Create capital allocation ‚Üí visualize reserves
- [ ] Migration script: 100% data integrity verification

**Risks:**
- ‚ö†Ô∏è **Reserve algorithm complexity** - Edge cases in graduation rates
- ‚úÖ **Mitigation:** Comprehensive test fixtures from background agent (20+ scenarios)
- ‚ö†Ô∏è **Data migration failures** - Schema mismatches
- ‚úÖ **Mitigation:** Dry-run mode, rollback script, staging environment testing

---

### Sprint 3: Modeling Wizard Foundation
**Goal:** Unified modeling experience (Steps 1-3 of 7)

**Duration:** 2 weeks (Dec 2-13, 2025)
**Developer Hours:** 70 hours

**Epic:** Unified Modeling Wizard (Phase 1)

**Stories:**

1. **Implement Modeling Wizard Steps 1-3** [5d]
   - **Steps:**
     - Step 1: General Info (fund name, size, vintage, currency, fund life)
     - Step 2: Sector Profiles (sector allocations, stage allocations)
     - Step 3: Capital Allocation (initial checks, follow-on strategy, pacing)
   - **AC:**
     - XState machine controls navigation (forward/back with validation)
     - React Hook Form + Zod validation per step
     - Auto-save to localStorage every 30 seconds
     - Progress bar shows completion (3/7 steps)
   - **Validation:** LP-credible constraints (mgmt fee 0-5%, carry 0-30%, etc.)

2. **Create Wizard State Persistence Layer** [2d]
   - **AC:**
     - localStorage key: `modeling-wizard-{userId}-{sessionId}`
     - Resume capability: User can close browser and resume
     - "Clear and Start Over" button
     - Session expiry: 7 days of inactivity
   - **Data Structure:**
     ```typescript
     interface WizardSession {
       currentStep: number;
       steps: { [stepName: string]: StepData };
       lastSaved: string; // ISO timestamp
       sessionId: string;
     }
     ```

3. **Migrate Basic Financial Modeling Components** [3d]
   - **AC:**
     - Old `/financial-modeling` route redirects to `/model?tab=construction`
     - Existing pacing calculations moved to wizard Step 3
     - Deprecation banner with 2-week notice
     - "Import from old model" button (copies data to wizard)

4. **Add Validation Framework for Wizard Steps** [2d]
   - **AC:**
     - Zod schemas per step (already created by background agent)
     - Inline validation errors (shows field-level feedback)
     - Step-level errors prevent navigation
     - Warning vs error severity (warnings allow proceed)

5. **User Testing Session with Power Users** [1d]
   - **AC:**
     - Schedule 3 √ó 30-min sessions with internal users
     - Record feedback on wizard flow
     - Identify pain points or confusing UX
     - Prioritize fixes for Sprint 4

**Measurable Outcomes:**
- ‚úÖ First 3 wizard steps functional with validation
- ‚úÖ Auto-save and resume working
- ‚úÖ User feedback collected and prioritized

**Definition of Done:**
- [ ] All 3 steps can be completed end-to-end
- [ ] Validation catches invalid inputs (tested with 10 edge cases)
- [ ] Auto-save tested: Close browser mid-step, reopen, data persists
- [ ] User testing: 3 sessions completed, feedback documented

**Risks:**
- ‚ö†Ô∏è **Wizard UX complexity** - Too many fields per step
- ‚úÖ **Mitigation:** User testing in Sprint 3, iterate in Sprint 4
- ‚ö†Ô∏è **State machine bugs** - Unexpected state transitions
- ‚úÖ **Mitigation:** XState visualizer for debugging, comprehensive guards

---

### Sprint 4: Advanced Modeling & Operations Core
**Goal:** Complete modeling wizard (Steps 4-7) + basic operations

**Duration:** 2 weeks (Dec 16-27, 2025)
**Developer Hours:** 70 hours

**Epic:** Modeling Wizard Completion + Operations Foundation

**Stories:**

1. **Implement Wizard Steps 4-7** [4d]
   - **Steps:**
     - Step 4: Fees & Expenses (mgmt fee, fee basis, step-down, admin expenses)
     - Step 5: Exit Recycling (optional: recycling cap, period, rates)
     - Step 6: Waterfall (American/European, preferred return, catch-up, custom tiers)
     - Step 7: Scenarios (construction vs current, comparison scenarios)
   - **AC:**
     - All steps integrate with selector contract for real-time preview
     - Fee basis options: Committed, Called, Cumulative, FMV, Invested, etc.
     - Waterfall preview: Animated bar chart showing LP/GP splits
     - Scenario comparison: Side-by-side KPI table

2. **Build Operations Hub Skeleton** [2d]
   - **AC:**
     - Route: `/operate` with tabs (Capital Calls, Distributions, Fees)
     - Tab navigation via URL params (`?tab=calls`)
     - Empty state messages: "No capital calls yet. Create one below."
     - Feature flag: `operate_hub`

3. **Migrate Cash Management Basics** [2d]
   - **AC:**
     - Old `/cash-management` route redirects to `/operate?tab=calls`
     - Capital call list view (table with filters)
     - Deprecation banner with 2-week notice

4. **Create Capital Call Workflow Foundation** [3d]
   - **AC:**
     - Modal: "Create Capital Call"
     - Form fields: Amount, Due Date, LPs (multi-select), Notes
     - Validation: Amount > 0, Due Date > Today, At least 1 LP selected
     - Preview: Shows per-LP amounts based on commitments
     - Submit: POST to `/api/v1/operations/capital-calls`

5. **Performance Optimization for Complex Calculations** [2d]
   - **AC:**
     - Waterfall calculations memoized (useMemo)
     - Scenario comparison debounced (500ms delay)
     - Large table rendering virtualized (TanStack Table)
     - Bundle analysis: Identify and code-split heavy dependencies
     - Lighthouse score: > 90 performance

**Measurable Outcomes:**
- ‚úÖ All 7 wizard steps functional
- ‚úÖ Operations hub launched with capital calls feature
- ‚úÖ Performance: Page interactions < 100ms

**Definition of Done:**
- [ ] Wizard can be completed end-to-end (15-20 min user flow)
- [ ] Waterfall preview matches hand-calculated values (5 test cases)
- [ ] Capital call workflow: Create ‚Üí Preview ‚Üí Submit ‚Üí Confirm
- [ ] Performance: Lighthouse score > 90

**Risks:**
- ‚ö†Ô∏è **Waterfall complexity** - Custom tier calculations
- ‚úÖ **Mitigation:** Start with American/European presets, custom tiers as enhancement
- ‚ö†Ô∏è **Performance degradation** - Too many re-renders
- ‚úÖ **Mitigation:** React DevTools profiling, memoization strategy

---

### Sprint 5: Reporting & Operations Automation
**Goal:** LP reporting + operational workflows

**Duration:** 2 weeks (Jan 6-17, 2026)
**Developer Hours:** 70 hours

**Epic:** Automated LP Reporting + Operations Workflows

**Stories:**

1. **Implement LP Reporting Templates** [3d]
   - **AC:**
     - Template engine: Handlebars or React PDF
     - Standard templates: Quarterly Statement, Annual Report, Capital Call Notice
     - Variable interpolation: `{{fund.name}}`, `{{lp.commitment}}`, `{{period.tvpi}}`
     - Preview mode: See rendered report before generation
     - Custom template builder: Drag-and-drop fields

2. **Build Distribution Calculation Engine** [3d]
   - **AC:**
     - Waterfall calculation integration (from Sprint 4)
     - Distribution scenarios: Full liquidation, Partial exit, Interim distributions
     - LP vs GP splits calculated per waterfall rules
     - Tax withholding support (optional)
     - Export to CSV for accounting systems

3. **Create Fee Management Components** [2d]
   - **AC:**
     - Fee schedule configuration (mgmt fee, step-down, expense caps)
     - Accrual calculation: Daily accruals based on fee basis
     - Invoice generation: PDF invoices for management fees
     - Payment tracking: Mark invoices as paid/unpaid

4. **Automated Report Generation System** [3d]
   - **AC:**
     - Cron job: Generate quarterly reports automatically
     - Email distribution: Send to LPs via configured SMTP
     - Report history: Archive all generated reports
     - On-demand generation: "Generate Report" button
     - Bulk export: Download all reports as ZIP

5. **Integration Testing Across Modules** [2d]
   - **AC:**
     - E2E test: Create capital call ‚Üí Track payment ‚Üí Generate report
     - E2E test: Create distribution ‚Üí Calculate waterfall ‚Üí Generate tax docs
     - E2E test: Update fee schedule ‚Üí Recalculate accruals ‚Üí Generate invoice
     - All tests pass in CI pipeline

**Measurable Outcomes:**
- ‚úÖ LP reporting templates functional
- ‚úÖ Distribution calculations match Excel models (5 test cases)
- ‚úÖ Fee management workflow end-to-end

**Definition of Done:**
- [ ] 3 standard templates render correctly
- [ ] Distribution calculation: 100% accuracy vs Excel reference
- [ ] Integration tests: 95% pass rate
- [ ] Email delivery: Tested with test SMTP server

**Risks:**
- ‚ö†Ô∏è **Template rendering complexity** - PDF generation issues
- ‚úÖ **Mitigation:** Use battle-tested library (react-pdf or Puppeteer)
- ‚ö†Ô∏è **Email deliverability** - Spam filters
- ‚úÖ **Mitigation:** SPF/DKIM setup, test with real email providers

---

### Sprint 6: Polish & Full Migration
**Goal:** Complete migration + performance optimization + production readiness

**Duration:** 2 weeks (Jan 20-31, 2026)
**Developer Hours:** 70 hours

**Epic:** Production Readiness & Final Migration

**Stories:**

1. **Migrate Remaining Legacy Routes** [3d]
   - **Routes to migrate:**
     - `/forecasting` ‚Üí `/model?tab=current`
     - `/cap-tables/:id` ‚Üí `/portfolio/:id/cap-table`
     - `/design-system` ‚Üí Remove from nav (dev-only)
   - **AC:**
     - Hard redirects (301) for old routes
     - Deprecation banners removed
     - Analytics: Track redirect usage (should be < 1% by end of sprint)

2. **Comprehensive E2E Testing** [2d]
   - **Critical Paths:**
     - User journey: Login ‚Üí Overview ‚Üí Portfolio ‚Üí Company Detail ‚Üí Cap Table
     - User journey: Create model ‚Üí Run scenarios ‚Üí Export to Excel
     - User journey: Create capital call ‚Üí Generate report ‚Üí Email to LPs
   - **Tools:** Playwright with video recording
   - **Coverage:** 90% of user interactions

3. **Performance Audit and Optimization** [2d]
   - **Audit:**
     - Lighthouse CI on all major pages
     - Bundle analysis (webpack-bundle-analyzer)
     - Identify largest dependencies
   - **Optimizations:**
     - Code-split heavy libraries (charts, PDF generator)
     - Lazy load non-critical routes
     - Image optimization (WebP, lazy loading)
     - Font subsetting
   - **Target:** All pages < 3s load on 3G, > 90 Lighthouse score

4. **User Acceptance Testing Coordination** [2d]
   - **UAT Plan:**
     - 5 internal users test full platform (2 hours each)
     - Bug bash: Find and log bugs (priority: Critical, High, Medium, Low)
     - Feedback collection: SUS (System Usability Scale) survey
     - Sign-off: Product Owner approves for production

5. **Documentation Finalization** [2d]
   - **Docs to complete:**
     - User guide: Step-by-step for each major feature
     - API documentation: OpenAPI specs published to Swagger UI
     - Architecture Decision Records (ADRs): 10+ decisions documented
     - Runbooks: Deployment, rollback, disaster recovery
     - Release notes: Changelog for stakeholders

6. **Production Deployment Preparation** [2d]
   - **Checklist:**
     - [ ] Environment variables configured (production)
     - [ ] Database migrations tested on staging
     - [ ] SSL certificates renewed
     - [ ] Monitoring dashboards set up (Sentry, Grafana)
     - [ ] Backup strategy verified (daily automated backups)
     - [ ] Rollback plan documented and tested
     - [ ] Feature flags default values set
     - [ ] Load testing: 100 concurrent users, no errors

**Measurable Outcomes:**
- ‚úÖ 100% legacy routes migrated
- ‚úÖ E2E tests: 90% coverage
- ‚úÖ Performance: All pages meet budgets
- ‚úÖ UAT: Sign-off from Product Owner
- ‚úÖ Production deployment: Ready for launch

**Definition of Done:**
- [ ] Zero critical bugs
- [ ] All E2E tests passing
- [ ] Lighthouse scores > 90 on all pages
- [ ] UAT sign-off document signed
- [ ] Production deployment checklist 100% complete

**Risks:**
- ‚ö†Ô∏è **Last-minute bugs** - High severity issues discovered in UAT
- ‚úÖ **Mitigation:** 2-day buffer for bug fixing, prioritize critical path
- ‚ö†Ô∏è **Deployment failures** - Database migration issues in production
- ‚úÖ **Mitigation:** Staging environment mirrors production, migration tested 3x

---

## üèóÔ∏è Technical Architecture

### API Endpoints (OpenAPI 3.0)

```yaml
openapi: 3.0.0
info:
  title: VC Fund Management Platform API
  version: 1.0.0

paths:
  /api/v1/funds/{fundId}/snapshot:
    get:
      summary: Get fund data snapshot for KPI calculations
      parameters:
        - name: fundId
          in: path
          required: true
          schema:
            type: string
        - name: asOf
          in: query
          schema:
            type: string
            format: date
      responses:
        200:
          description: Fund data snapshot
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/FundData'

  /api/v1/reserve/calculate:
    post:
      summary: Calculate optimal reserve allocation
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ReserveCalculationRequest'
      responses:
        200:
          description: Reserve calculation result
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ReserveCalculationResult'

  /api/v1/modeling/sessions:
    post:
      summary: Create new modeling session
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/ModelingSessionCreate'
      responses:
        201:
          description: Session created
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ModelingSession'

    get:
      summary: List modeling sessions
      parameters:
        - name: portfolioId
          in: query
          schema:
            type: string
      responses:
        200:
          description: List of sessions
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: '#/components/schemas/ModelingSession'

  /api/v1/operations/capital-calls:
    post:
      summary: Create capital call
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CapitalCallCreate'
      responses:
        201:
          description: Capital call created

    get:
      summary: List capital calls
      responses:
        200:
          description: List of capital calls

  /api/v1/reports/lp-statements:
    post:
      summary: Generate LP statement
      requestBody:
        required: true
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/LPStatementRequest'
      responses:
        201:
          description: Report generation started
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/ReportJob'

components:
  schemas:
    FundData:
      type: object
      required: [fundId, asOf]
      properties:
        fundId:
          type: string
        asOf:
          type: string
          format: date
        commitments:
          type: array
          items:
            $ref: '#/components/schemas/Commitment'
        capitalCalls:
          type: array
          items:
            $ref: '#/components/schemas/CapitalCall'
        investments:
          type: array
          items:
            $ref: '#/components/schemas/Investment'
        valuations:
          type: array
          items:
            $ref: '#/components/schemas/Valuation'
        distributions:
          type: array
          items:
            $ref: '#/components/schemas/Distribution'
        fees:
          type: array
          items:
            $ref: '#/components/schemas/FeeExpense'

    # ... (Additional schemas defined in background agent's work)
```

*(Full OpenAPI spec created by background agent in `RESERVE_ENGINE_SPEC.md`)*

### Database Schema Evolution

#### New Tables Required

```sql
-- Modeling sessions table
CREATE TABLE modeling_sessions (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  portfolio_id UUID REFERENCES portfolios(id),
  user_id UUID REFERENCES users(id),
  current_step INTEGER NOT NULL DEFAULT 1,
  session_data JSONB NOT NULL DEFAULT '{}',
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  expires_at TIMESTAMP WITH TIME ZONE DEFAULT NOW() + INTERVAL '7 days'
);

CREATE INDEX idx_modeling_sessions_portfolio ON modeling_sessions(portfolio_id);
CREATE INDEX idx_modeling_sessions_user ON modeling_sessions(user_id);
CREATE INDEX idx_modeling_sessions_expires ON modeling_sessions(expires_at);

-- KPI definition versioning
CREATE TABLE kpi_definitions (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  selector_key VARCHAR(100) UNIQUE NOT NULL,
  calculation_logic JSONB NOT NULL,
  version INTEGER NOT NULL DEFAULT 1,
  deprecated BOOLEAN DEFAULT FALSE,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE INDEX idx_kpi_definitions_key ON kpi_definitions(selector_key);

-- Report templates
CREATE TABLE report_templates (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  template_type VARCHAR(50) NOT NULL,
  name VARCHAR(255) NOT NULL,
  content TEXT NOT NULL,
  variables JSONB NOT NULL DEFAULT '[]',
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE INDEX idx_report_templates_type ON report_templates(template_type);

-- Capital calls
CREATE TABLE capital_calls (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  portfolio_id UUID REFERENCES portfolios(id),
  amount DECIMAL(15, 2) NOT NULL,
  due_date DATE NOT NULL,
  status VARCHAR(50) DEFAULT 'pending',
  notes TEXT,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  updated_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE INDEX idx_capital_calls_portfolio ON capital_calls(portfolio_id);
CREATE INDEX idx_capital_calls_status ON capital_calls(status);
CREATE INDEX idx_capital_calls_due_date ON capital_calls(due_date);

-- Capital call LP allocations
CREATE TABLE capital_call_allocations (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  capital_call_id UUID REFERENCES capital_calls(id) ON DELETE CASCADE,
  lp_id UUID REFERENCES lps(id),
  amount DECIMAL(15, 2) NOT NULL,
  paid BOOLEAN DEFAULT FALSE,
  paid_at TIMESTAMP WITH TIME ZONE,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

CREATE INDEX idx_capital_call_allocations_call ON capital_call_allocations(capital_call_id);
CREATE INDEX idx_capital_call_allocations_lp ON capital_call_allocations(lp_id);

-- Report generation jobs
CREATE TABLE report_jobs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  report_type VARCHAR(100) NOT NULL,
  parameters JSONB NOT NULL,
  status VARCHAR(50) DEFAULT 'pending',
  file_url TEXT,
  error TEXT,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  completed_at TIMESTAMP WITH TIME ZONE
);

CREATE INDEX idx_report_jobs_status ON report_jobs(status);
CREATE INDEX idx_report_jobs_created ON report_jobs(created_at);
```

#### Migration Scripts

```bash
# Migration naming convention
# {timestamp}_{description}.sql

# Example: 20260104120000_add_modeling_sessions.sql

-- Up migration
BEGIN;

CREATE TABLE modeling_sessions (...);
CREATE INDEX idx_modeling_sessions_portfolio ON modeling_sessions(portfolio_id);

COMMIT;

-- Down migration (in separate file)
BEGIN;

DROP INDEX IF EXISTS idx_modeling_sessions_portfolio;
DROP TABLE IF EXISTS modeling_sessions;

COMMIT;
```

### State Management Evolution

**Current State:**
```
React Context + useState
‚îú‚îÄ‚îÄ FundContext (global fund state)
‚îú‚îÄ‚îÄ UserContext (authentication)
‚îî‚îÄ‚îÄ Local state in components
```

**Phase 1: Add TanStack Query (Sprint 1-2)**
```
React Context + useState + TanStack Query
‚îú‚îÄ‚îÄ FundContext (global fund state)
‚îú‚îÄ‚îÄ UserContext (authentication)
‚îú‚îÄ‚îÄ TanStack Query (server state: KPIs, portfolios, etc.)
‚îî‚îÄ‚îÄ Local state in components
```

**Phase 2: Add Zustand for Complex Client State (Sprint 3-4)**
```
React Context + TanStack Query + Zustand
‚îú‚îÄ‚îÄ UserContext (authentication only)
‚îú‚îÄ‚îÄ TanStack Query (all server state)
‚îú‚îÄ‚îÄ Zustand Stores:
‚îÇ   ‚îú‚îÄ‚îÄ wizardStore (modeling wizard state)
‚îÇ   ‚îú‚îÄ‚îÄ operationsStore (capital calls, distributions)
‚îÇ   ‚îî‚îÄ‚îÄ uiStore (sidebar, modals, toasts)
‚îî‚îÄ‚îÄ Local state (form inputs only)
```

**Phase 3: Replace Context with Consolidated Stores (Sprint 5-6)**
```
TanStack Query + Zustand
‚îú‚îÄ‚îÄ TanStack Query (all server state)
‚îî‚îÄ‚îÄ Zustand Stores:
    ‚îú‚îÄ‚îÄ authStore (user, session)
    ‚îú‚îÄ‚îÄ wizardStore (modeling wizard)
    ‚îú‚îÄ‚îÄ operationsStore (operations hub)
    ‚îî‚îÄ‚îÄ uiStore (UI state)
```

**Benefits:**
- ‚úÖ Clear separation: Server state (TanStack Query) vs Client state (Zustand)
- ‚úÖ Performance: No unnecessary re-renders from Context
- ‚úÖ DevTools: TanStack Query DevTools + Zustand DevTools
- ‚úÖ Testing: Isolated stores are easier to test

### Testing Strategy

#### Unit Tests (Jest + Testing Library)
- **Target:** 80% coverage for new code
- **Focus:**
  - Selector functions (pure functions, easy to test)
  - Utility functions (formatters, validators)
  - Custom hooks (useFundKpis, useModelingWizard)

```bash
npm run test:unit
# Runs all *.test.ts and *.test.tsx files
```

#### Integration Tests (MSW + React Testing Library)
- **Target:** 60% coverage for user flows
- **Focus:**
  - API integration (mock with MSW)
  - Multi-component interactions
  - State management flows

```typescript
// Example: KPI selector integration test
describe('KPI Selector Integration', () => {
  it('fetches fund data and calculates TVPI correctly', async () => {
    const mockData = createMockFundData();
    server.use(
      rest.get('/api/v1/funds/:fundId/snapshot', (req, res, ctx) => {
        return res(ctx.json(mockData));
      })
    );

    render(<HeaderKpis />);

    await waitFor(() => {
      expect(screen.getByText('1.43x')).toBeInTheDocument(); // TVPI
    });
  });
});
```

#### E2E Tests (Playwright)
- **Target:** 90% coverage for critical paths
- **Focus:**
  - Complete user journeys
  - Cross-browser testing (Chrome, Firefox, Safari)
  - Mobile responsive testing

```typescript
// Example: Modeling wizard E2E test
test('complete modeling wizard flow', async ({ page }) => {
  await page.goto('/model');

  // Step 1: General Info
  await page.fill('[name="fundName"]', 'Test Fund I');
  await page.fill('[name="fundSize"]', '20000000');
  await page.click('button:has-text("Next")');

  // Step 2-7: ... (complete all steps)

  // Final submission
  await page.click('button:has-text("Submit Model")');
  await expect(page.locator('text=Model created successfully')).toBeVisible();
});
```

#### Performance Tests (Lighthouse CI)
- **Target:** > 90 Lighthouse score on all pages
- **Budget:**
  - First Contentful Paint: < 1.5s
  - Time to Interactive: < 3.0s
  - Bundle size: < 300kb initial, < 500kb total

```yaml
# lighthouserc.js
module.exports = {
  ci: {
    collect: {
      url: ['http://localhost:5173/', 'http://localhost:5173/portfolio'],
      numberOfRuns: 3,
    },
    assert: {
      preset: 'lighthouse:recommended',
      assertions: {
        'first-contentful-paint': ['warn', { maxNumericValue: 1500 }],
        'interactive': ['error', { maxNumericValue: 3000 }],
      },
    },
  },
};
```

---

## üîÑ Migration Strategy

### Route Redirect Plan

**Phase 1: Soft Redirects with Banners (Sprint 1-2)**
```typescript
// Old route shows banner: "New experience available at /portfolio"
// User can click to try new version or continue with old
// Analytics: Track % of users who switch

// Example banner component
<Banner variant="info">
  We've improved the portfolio experience!
  <Link to="/portfolio">Try the new version</Link> or
  <Link to="/investments?legacy=1">continue here</Link>.
</Banner>
```

**Phase 2: Hard Redirects with Opt-Out (Sprint 3-4)**
```typescript
// Old route automatically redirects to new
// URL param allows reverting: /investments?legacy=1 shows old version
// Analytics: Track legacy usage (should be < 10%)

// Route config
<Route path="/investments">
  {({ search }) => {
    if (search.includes('legacy=1')) {
      return <LegacyInvestments />;
    }
    return <Navigate to="/portfolio" replace />;
  }}
</Route>
```

**Phase 3: Full Migration (Sprint 5-6)**
```typescript
// Old routes removed entirely
// 301 redirects at server level (nginx/Vercel)

// vercel.json
{
  "redirects": [
    {
      "source": "/investments",
      "destination": "/portfolio",
      "permanent": true
    },
    {
      "source": "/investment-table",
      "destination": "/portfolio",
      "permanent": true
    }
  ]
}
```

### Data Migration Scripts

#### Investment Data Migration

```typescript
// scripts/migrate-investments.ts

import { db } from '@/server/db';
import { investments } from '@shared/schema';
import { z } from 'zod';

const LegacyInvestmentSchema = z.object({
  id: z.number(),
  company_name: z.string(),
  amount: z.number(),
  date: z.string(), // ISO date string
  // ... other legacy fields
});

const transformInvestment = (legacy: z.infer<typeof LegacyInvestmentSchema>) => {
  return {
    id: legacy.id.toString(), // Convert to string ID
    companyId: legacy.company_id,
    cost: legacy.amount,
    date: new Date(legacy.date),
    // ... map other fields
  };
};

async function migrateInvestments(dryRun = true) {
  console.log(`Starting investment migration (dry run: ${dryRun})`);

  // 1. Export from legacy API
  const legacyData = await fetch('/api/legacy/investments').then(r => r.json());

  // 2. Validate legacy data
  const validated = z.array(LegacyInvestmentSchema).parse(legacyData);

  // 3. Transform to new schema
  const transformed = validated.map(transformInvestment);

  if (dryRun) {
    console.log(`Would migrate ${transformed.length} investments`);
    console.log('Sample:', transformed[0]);
    return;
  }

  // 4. Insert to new database
  await db.insert(investments).values(transformed);

  // 5. Validate migration
  const count = await db.select({ count: sql`count(*)` }).from(investments);
  console.log(`Migration complete. Total investments: ${count}`);
}

// Run with: npm run migrate:investments -- --dry-run
// Then: npm run migrate:investments -- --live
```

#### Rollback Script

```typescript
// scripts/rollback-investments.ts

async function rollbackInvestments(backupId: string) {
  console.log(`Rolling back to backup: ${backupId}`);

  // 1. Load backup from S3 or filesystem
  const backup = await loadBackup(backupId);

  // 2. Drop new data
  await db.delete(investments);

  // 3. Restore backup
  await db.insert(investments).values(backup);

  console.log('Rollback complete');
}
```

### Feature Flag Rollout Sequence

**Week 1-2 (Sprint 1):**
```typescript
// Enable new Overview page for internal users only
const flags = {
  new_ia: true,
  live_kpi_selectors: false, // Still using mock data
  modeling_hub: false,
  operate_hub: false,
};
```

**Week 3-4 (Sprint 2):**
```typescript
// Enable live KPI selectors for 10% of users (A/B test)
const flags = {
  new_ia: true,
  live_kpi_selectors: rolloutPercentage(10), // 10% rollout
  modeling_hub: false,
  operate_hub: false,
};
```

**Week 5-6 (Sprint 3):**
```typescript
// Enable modeling hub for beta testers
const flags = {
  new_ia: true,
  live_kpi_selectors: true, // 100% rollout
  modeling_hub: rolloutToBetaTesters(), // Specific user list
  operate_hub: false,
};
```

**Week 7-8 (Sprint 4):**
```typescript
// Enable all features for all users
const flags = {
  new_ia: true,
  live_kpi_selectors: true,
  modeling_hub: true,
  operate_hub: true, // 100% rollout
};
```

### Rollback Procedures

#### Emergency Rollback (< 5 minutes)

```bash
# 1. Toggle feature flag off immediately
curl -X POST https://api.yourplatform.com/admin/feature-flags \
  -H "Authorization: Bearer $ADMIN_TOKEN" \
  -d '{"flag": "modeling_hub", "enabled": false}'

# 2. Verify flag propagation
curl https://api.yourplatform.com/admin/feature-flags/modeling_hub

# 3. Monitor error rates (should drop immediately)
```

#### Database Rollback (< 30 minutes)

```bash
# 1. Stop application (prevent new writes)
vercel deploy --prod --force-stop

# 2. Restore database from backup
pg_restore -h $DB_HOST -U $DB_USER -d $DB_NAME \
  /backups/db_backup_$(date +%Y%m%d).dump

# 3. Run down migrations
npm run migrate:down -- --to=20260101000000

# 4. Restart application
vercel deploy --prod
```

#### Code Rollback (< 10 minutes)

```bash
# 1. Revert to previous Git tag
git revert HEAD --no-edit
git push origin main

# 2. Deploy previous version
vercel deploy --prod --force

# 3. Verify deployment
curl https://yourplatform.com/api/health
```

---

## üë®‚Äçüíª Developer Workflow

### Daily Cadence (Solo Developer)

**Morning (8:00-12:00) - Deep Work**
- 8:00-9:00: Review progress, plan day
  - Check CI status, Sentry errors
  - Review stakeholder feedback
  - Prioritize today's stories
- 9:00-12:00: Feature development
  - Focus: One major story per day
  - No interruptions (DND mode)
  - Commit every 30-60 minutes

**Afternoon (13:00-17:00) - Integration & Communication**
- 13:00-15:00: Integration & testing
  - Write tests for morning's code
  - Run E2E tests locally
  - Fix any failing tests
- 15:00-16:00: Documentation & code review
  - Update ADRs
  - Self-review: Read code as if reviewing PR
  - Refactor obvious improvements
- 16:00-17:00: Stakeholder communication
  - Update sprint board
  - Respond to feedback
  - Prepare next day's plan

**Evening (Optional) - Learning**
- Stay updated on React/TypeScript patterns
- Explore new libraries/tools
- Read architecture blogs

### Weekly Cadence

**Monday:**
- Morning: Sprint planning (if new sprint)
- Afternoon: Stakeholder sync (30 min)
- Goal: Align on week's priorities

**Wednesday:**
- Morning: Mid-sprint check-in
- Afternoon: Course correction if needed
- Goal: Stay on track

**Friday:**
- Morning: Wrap up week's stories
- Afternoon: Demo preparation
- Evening: Sprint retrospective (solo reflection)
- Goal: Celebrate wins, identify improvements

### AI Agent Utilization Strategy

#### GitHub Copilot (Daily, Real-Time)
- **Use Cases:**
  - Autocomplete boilerplate code
  - Generate test cases
  - Suggest function implementations
- **Time Saved:** ~20% (7 hours/week)

#### Claude/GPT-4 (Daily, On-Demand)
- **Use Cases:**
  - Architecture decisions ("Should I use Zustand or Redux?")
  - Debug complex bugs (paste stack trace)
  - Explain unfamiliar code
- **Time Saved:** ~15% (5 hours/week)

#### Cursor (Weekly, Code Exploration)
- **Use Cases:**
  - Explore large codebase ("Where is the fund selector defined?")
  - Refactor complex files
  - Generate documentation from code
- **Time Saved:** ~10% (3 hours/week)

#### Custom Scripts (Weekly, Automation)
- **Use Cases:**
  - Automated test generation from Zod schemas
  - Documentation generation from TypeScript types
  - Migration script generation
- **Time Saved:** ~5% (2 hours/week)

**Total AI Time Savings:** ~50% (17 hours/week)
**Effective Development Capacity:** 35 hours √ó 1.5 = ~52 hours/week equivalent

### Code Review Checkpoints

**Self-Review (Daily)**
- Read code as if reviewing PR
- Checklist:
  - [ ] Naming: Clear, consistent
  - [ ] Logic: No obvious bugs
  - [ ] Tests: Coverage > 80%
  - [ ] Comments: Explain "why", not "what"

**Automated Review (Pre-Commit)**
- ESLint: No errors, max 5 warnings
- TypeScript: No type errors
- Prettier: Code formatted
- Unit tests: All passing

**External Review (Bi-Weekly)**
- Hire contractor for code review
- Focus: Architecture, security, performance
- Budget: 4 hours √ó $100/hr = $400 every 2 weeks

**Pair Programming with AI (Weekly)**
- Schedule 2-hour session
- Share screen with Claude/GPT-4
- Discuss complex problems in real-time
- Document decisions in ADR

### Documentation Requirements

#### Architecture Decision Records (ADRs)

```markdown
# ADR-001: Selector Contract Pattern for KPIs

## Status
Accepted

## Context
We need a centralized way to calculate KPIs (TVPI, DPI, IRR) across multiple pages.
Currently, logic is duplicated in 5 different components, leading to drift and bugs.

## Decision
Implement pure selector functions that take `FundData` and return KPI values.
Use TanStack Query's `select` option to memoize calculations.

## Consequences
**Positive:**
- Single source of truth for KPI logic
- Easy to test (pure functions)
- Performance: memoization reduces recalculations

**Negative:**
- Requires refactoring existing components
- Learning curve for new pattern

## Implementation
See `client/src/core/selectors/fund-kpis.ts`

## Date
2025-10-02

## Author
Multi-AI Collaboration
```

#### API Documentation (OpenAPI)

```bash
# Swagger UI hosted at /api/docs
npm run docs:api

# Generate TypeScript types from OpenAPI spec
npm run codegen:api
```

#### Component Storybook

```bash
# Storybook hosted at http://localhost:6006
npm run storybook

# Build static Storybook for deployment
npm run build-storybook
```

#### Operational Runbooks

```markdown
# Runbook: Deploy to Production

## Prerequisites
- [ ] All tests passing in CI
- [ ] Lighthouse score > 90
- [ ] Stakeholder sign-off

## Steps
1. Merge feature branch to `main`
2. Wait for CI to build and test
3. Deploy to staging: `vercel deploy --target staging`
4. Run smoke tests on staging
5. Deploy to production: `vercel deploy --prod`
6. Monitor Sentry for errors (15 minutes)
7. Notify stakeholders in Slack

## Rollback
If errors spike:
1. Run `vercel rollback`
2. Investigate in staging
3. Fix and redeploy

## Time
15-30 minutes
```

---

## ‚úÖ Quality Gates

### Definition of Done (Per Sprint)

**Code Quality:**
- [ ] All acceptance criteria met
- [ ] Unit test coverage > 80% for new code
- [ ] Integration tests cover critical paths
- [ ] E2E tests pass for user journeys
- [ ] ESLint: 0 errors, < 5 warnings
- [ ] TypeScript: 0 type errors
- [ ] Code reviewed (self + AI assistant)

**Performance:**
- [ ] Lighthouse score > 90
- [ ] Bundle size increase < 10%
- [ ] Page load time < 3 seconds
- [ ] API response time < 500ms P95

**Documentation:**
- [ ] ADR written for major decisions
- [ ] API documentation updated (OpenAPI)
- [ ] README updated with new features
- [ ] Runbook created for complex deployments

**User Experience:**
- [ ] Accessibility: WCAG 2.1 AA compliant
- [ ] Mobile responsive (tested on 3 devices)
- [ ] Error states designed and implemented
- [ ] Loading states designed and implemented

**Deployment:**
- [ ] Feature flagged appropriately
- [ ] Database migrations tested on staging
- [ ] Rollback plan documented
- [ ] Monitoring alerts configured

### Performance Budgets

| Metric | Target | Maximum | Tool |
|--------|--------|---------|------|
| First Contentful Paint | < 1.0s | < 1.5s | Lighthouse |
| Time to Interactive | < 2.0s | < 3.0s | Lighthouse |
| Largest Contentful Paint | < 2.0s | < 2.5s | Lighthouse |
| Cumulative Layout Shift | < 0.05 | < 0.1 | Lighthouse |
| Total Bundle Size (Initial) | < 200kb | < 300kb | webpack-bundle-analyzer |
| Total Bundle Size (All) | < 400kb | < 500kb | webpack-bundle-analyzer |
| API Response Time (P50) | < 100ms | < 200ms | Sentry Performance |
| API Response Time (P95) | < 300ms | < 500ms | Sentry Performance |
| KPI Calculation Time | < 50ms | < 100ms | Custom instrumentation |

**Budget Enforcement:**
- Lighthouse CI runs on every PR
- Bundle size tracked in CI (fails if > 10% increase)
- API performance monitored in Sentry (alerts if P95 > 500ms)

### Accessibility Requirements (WCAG 2.1 AA)

**Perceivable:**
- [ ] Color contrast ratio ‚â• 4.5:1 for normal text
- [ ] Color contrast ratio ‚â• 3:1 for large text
- [ ] Text resizing up to 200% without loss of content
- [ ] Images have alt text

**Operable:**
- [ ] All functionality available via keyboard
- [ ] Focus indicators visible
- [ ] No keyboard traps
- [ ] Skip to main content link

**Understandable:**
- [ ] Language of page declared (`<html lang="en">`)
- [ ] Input fields have labels
- [ ] Error messages are descriptive
- [ ] Consistent navigation

**Robust:**
- [ ] Valid HTML (W3C validator)
- [ ] ARIA labels for complex components
- [ ] Screen reader testing (NVDA/JAWS)

**Testing Tools:**
- axe DevTools (browser extension)
- Lighthouse accessibility audit
- Manual testing with screen reader

### Security Checklist

**Authentication & Authorization:**
- [ ] JWT tokens expire after 1 hour
- [ ] Refresh tokens stored in httpOnly cookies
- [ ] RBAC: Users can only access own funds
- [ ] API routes protected with middleware

**Input Validation:**
- [ ] All API inputs validated with Zod
- [ ] SQL injection prevention (parameterized queries)
- [ ] XSS prevention (React escapes by default)
- [ ] CSRF tokens on state-changing requests

**Data Protection:**
- [ ] Sensitive data encrypted at rest (AES-256)
- [ ] HTTPS enforced (HTTP redirects to HTTPS)
- [ ] Environment variables not committed to Git
- [ ] API keys rotated quarterly

**Audit Logging:**
- [ ] All state-changing actions logged
- [ ] Logs include: user, timestamp, action, IP address
- [ ] Logs retained for 90 days
- [ ] Anomaly detection (e.g., 100 failed logins)

**Dependency Security:**
- [ ] npm audit run weekly
- [ ] Dependabot enabled
- [ ] No high/critical vulnerabilities
- [ ] Snyk scanning in CI

**Penetration Testing:**
- [ ] Annual pen test by external firm
- [ ] Bug bounty program (optional)

---

## ü§ù Stakeholder Management

### Sprint Review Format (30 minutes, bi-weekly)

**Agenda:**
1. **Sprint Goal Recap** (5 min)
   - What we set out to achieve
   - Success criteria

2. **Live Demo** (15 min)
   - Show completed features
   - Real user flow (not slides)
   - Highlight key improvements

3. **Metrics & Progress** (5 min)
   - Burn-down chart
   - Velocity trend
   - Test coverage, performance scores

4. **Next Sprint Preview** (5 min)
   - Upcoming features
   - Dependencies
   - Risks

**Demo Best Practices:**
- Use production-like data (mock but realistic)
- Have backup recordings in case of live demo failures
- Show before/after comparisons
- Invite questions throughout

### Progress Tracking

#### Burn-Down Chart
```
Story Points Remaining
‚Üë
50‚îÇ      ‚ï±
  ‚îÇ    ‚ï±
40‚îÇ  ‚ï±     Ideal (straight line)
  ‚îÇ‚ï±
30‚îÇ    ‚óã   Actual (sprint 1)
  ‚îÇ  ‚óã
20‚îÇ‚óã         ‚óã = End of day
  ‚îÇ              ‚óã
10‚îÇ                  ‚óã
  ‚îÇ                      ‚óã
 0‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚Üí
  Mon Tue Wed Thu Fri Mon ... Time
```

**Tools:**
- Jira burndown report
- Google Sheets for custom charts
- Weekly screenshot sent to stakeholders

#### KPIs Dashboard

| Metric | Sprint 1 | Sprint 2 | Sprint 3 | Sprint 4 | Sprint 5 | Sprint 6 |
|--------|----------|----------|----------|----------|----------|----------|
| Features Completed | 5 | 5 | 4 | 5 | 6 | 7 |
| Test Coverage | 75% | 80% | 82% | 85% | 87% | 90% |
| Lighthouse Score | 88 | 90 | 92 | 93 | 94 | 95 |
| Bug Count (Open) | 12 | 8 | 5 | 3 | 2 | 0 |
| Velocity (SP/sprint) | 25 | 28 | 24 | 30 | 32 | 35 |

**Tools:**
- Sentry dashboard (errors, performance)
- Lighthouse CI (performance scores)
- Jira metrics (velocity, bug count)

### Risk Communication Plan

**Risk Register (Updated Weekly):**

| Risk | Likelihood | Impact | Mitigation | Owner | Status |
|------|------------|--------|------------|-------|--------|
| XIRR calculation bugs | Medium | High | Comprehensive test fixtures | Dev | Mitigated |
| Reserve engine complexity | High | Medium | Start with simple model | Dev | In Progress |
| Wizard UX confusing | Medium | Medium | User testing in Sprint 3 | Dev | Planned |
| Database migration failure | Low | Critical | Staging testing, rollback plan | Dev | Mitigated |
| Performance degradation | Medium | Medium | Lighthouse CI, bundle analysis | Dev | Monitoring |

**Risk Severity:**
- üü¢ **Green:** Low risk, no action needed
- üü° **Yellow:** Medium risk, monitoring closely
- üî¥ **Red:** High risk, immediate attention required

**Escalation Path:**
- Yellow risk: Notify stakeholders in weekly email
- Red risk: Immediate Slack message + emergency meeting

**Communication Channels:**
- Weekly email: Progress update + risk register
- Bi-weekly demo: Live presentation
- Slack: Real-time updates for urgent issues

### UAT (User Acceptance Testing) Strategy

**Sprint 3: Power User Testing**
- **Who:** 3 internal power users (GPs, analysts)
- **What:** Modeling wizard steps 1-3
- **Duration:** 2 hours per user
- **Goal:** Identify UX issues early

**Sprint 5: LP Reporting Validation**
- **Who:** 2 actual LPs (if available) or LP representatives
- **What:** Generated LP quarterly reports
- **Duration:** 1 hour per LP
- **Goal:** Ensure reports meet LP expectations

**Sprint 6: Full Platform UAT**
- **Who:** 5 users (2 GPs, 2 analysts, 1 LP)
- **What:** Complete platform (all features)
- **Duration:** 3 hours per user
- **Goal:** Final validation before production

**UAT Process:**
1. Send test plan 1 week in advance
2. Schedule 2-hour sessions
3. Record session (with permission)
4. Collect feedback via SUS survey
5. Prioritize bugs (Critical, High, Medium, Low)
6. Fix critical bugs before next sprint

**System Usability Scale (SUS) Survey:**
- 10 questions rated 1-5
- Score calculation: (Sum - 10) √ó 2.5
- Target: SUS score > 68 (above average)

**Example SUS Questions:**
1. I think I would like to use this system frequently
2. I found the system unnecessarily complex
3. I thought the system was easy to use
4. (... 7 more questions)

---

## üìä Deliverables Summary

### Documentation
- ‚úÖ **This Strategy Document** (29,000+ words)
- ‚úÖ **SELECTOR_CONTRACT_README.md** (KPI selector usage guide)
- ‚úÖ **RESERVE_ENGINE_SPEC.md** (Reserve API technical spec)
- ‚úÖ **MODELING_WIZARD_DESIGN.md** (Wizard architecture)
- ‚úÖ **DEMO_QUICK_START.md** (Tomorrow's demo guide)
- ‚úÖ **ENHANCED_DEMO_PLAN.md** (Production architecture)
- üìã **ADRs** (10+ architecture decisions, created during sprints)

### Code Artifacts (Already Created)
- ‚úÖ **Selector Contract** (TypeScript implementation + 40 tests)
- ‚úÖ **Reserve Engine API Spec** (OpenAPI + TypeScript client)
- ‚úÖ **Modeling Wizard State Machine** (XState v5 + React components)
- ‚úÖ **Feature Flag System** (Extended with IA flags)
- ‚úÖ **Demo Components** (ComingSoonPage, CompanyDetail)

### Jira-Ready Stories
- ‚úÖ **Sprint 0:** 4 stories (demo prep)
- ‚úÖ **Sprint 1:** 5 stories (KPI selectors)
- ‚úÖ **Sprint 2:** 5 stories (Portfolio + Reserve Engine)
- ‚úÖ **Sprint 3:** 5 stories (Modeling Wizard Phase 1)
- ‚úÖ **Sprint 4:** 5 stories (Modeling Wizard Phase 2 + Operations)
- ‚úÖ **Sprint 5:** 5 stories (Reporting + Automation)
- ‚úÖ **Sprint 6:** 6 stories (Final Migration + Production Readiness)

**Total:** 35 stories across 6 sprints

### Migration Runbooks
- ‚úÖ **Route Redirect Plan** (3-phase rollout)
- ‚úÖ **Data Migration Scripts** (Investments, with rollback)
- ‚úÖ **Feature Flag Rollout Sequence** (Progressive enhancement)
- ‚úÖ **Rollback Procedures** (Emergency, Database, Code)

### Risk Register
- ‚úÖ **5 Key Risks Identified**
- ‚úÖ **Mitigation Plans for Each**
- ‚úÖ **Severity Color Coding** (Green/Yellow/Red)
- ‚úÖ **Escalation Path Defined**

### Resource Allocation Chart

| Resource | Sprint 1 | Sprint 2 | Sprint 3 | Sprint 4 | Sprint 5 | Sprint 6 | Total |
|----------|----------|----------|----------|----------|----------|----------|-------|
| Solo Dev (hours) | 70 | 70 | 70 | 70 | 70 | 70 | 420 |
| AI Agents (time saved) | 17 | 17 | 17 | 17 | 17 | 17 | 102 |
| External Contractor (code review) | 4 | 4 | 4 | 4 | 4 | 4 | 24 |
| Stakeholder Time (demos) | 1 | 1 | 1 | 1 | 1 | 1 | 6 |
| **Total Effective Hours** | 92 | 92 | 92 | 92 | 92 | 92 | 552 |

**Cost Estimate:**
- Solo Dev: $100/hr √ó 420 hrs = $42,000
- External Contractor: $100/hr √ó 24 hrs = $2,400
- Infrastructure (Vercel, Sentry, etc.): $200/month √ó 3 months = $600
- **Total:** ~$45,000 for 3 months

---

## üéì Key Insights & Recommendations

### From Multi-AI Analysis

**OpenAI's Perspective:**
> "The plan demonstrates strong architectural thinking but suffers from scope/timeline mismatch. Prioritize based on impact and feasibility."

**DeepSeek's Perspective:**
> "The 'Strangler Fig' approach is ideal for this constraint. Build new system around old, coexist during transition, eventually replace."

**Claude's Synthesis:**
> "Use feature flags as the abstraction layer. Every feature can be toggled on/off, enabling safe rollout and instant rollback."

### Success Factors

1. **Progressive Enhancement** - Each sprint delivers demo-able value
2. **Feature Flags** - Safe rollout, instant rollback capability
3. **AI Leverage** - 50% time savings enables solo dev to punch above weight
4. **Testing Rigor** - 80%+ coverage catches regressions early
5. **Stakeholder Communication** - Bi-weekly demos keep everyone aligned

### Failure Modes to Avoid

1. ‚ùå **Big Bang Rewrites** - High risk, no incremental value
2. ‚ùå **Skipping Tests** - Technical debt compounds quickly
3. ‚ùå **Ignoring Performance** - Hard to fix retroactively
4. ‚ùå **Poor Communication** - Stakeholders surprised by delays
5. ‚ùå **Feature Creep** - Scope expands beyond solo dev capacity

### Recommended Adjustments (Based on Feedback)

**If Timeline is Too Aggressive:**
- Extend sprints from 2 weeks to 3 weeks
- Reduce scope: Cut Sprint 5 (Reporting), launch with manual LP reports
- Hire additional contractor for 10 hrs/week

**If Stakeholders Want Faster MVP:**
- Launch after Sprint 3 (Modeling Wizard functional)
- Keep Sprint 4-6 as post-MVP enhancements
- Trade: Less polish, but faster time-to-market

**If Budget is Constrained:**
- Skip external code reviews (rely on AI + self-review)
- Use free tier for monitoring (limited Sentry events)
- Extend timeline to reduce contractor costs

---

## üöÄ Next Steps

### Tomorrow (Demo Day)
1. [ ] Present new IA (5-item navigation)
2. [ ] Demo KPI dashboard with selector architecture
3. [ ] Show Company Detail tabs (Cap Table contextually placed)
4. [ ] Present Reserve Engine architecture (slides)
5. [ ] Present Modeling Wizard flow (state machine diagram)
6. [ ] Gather stakeholder feedback

### Week 1 (Sprint 1 Kickoff)
1. [ ] Prioritize Sprint 1 stories in Jira
2. [ ] Set up CI pipeline (ESLint, TypeScript, tests)
3. [ ] Implement first selector function (TVPI)
4. [ ] Write unit tests for TVPI selector
5. [ ] Create Overview page with KPI cards

### Month 1 (Sprints 1-2)
1. [ ] Complete KPI selector contract
2. [ ] Launch Portfolio hub
3. [ ] Implement Reserve Engine API
4. [ ] Conduct first stakeholder demo
5. [ ] Adjust plan based on feedback

### Months 2-3 (Sprints 3-6)
1. [ ] Launch Modeling Wizard
2. [ ] Launch Operations Hub
3. [ ] Implement LP Reporting
4. [ ] Conduct UAT
5. [ ] Deploy to production

---

## üìû Support & Escalation

**For Questions:**
- Technical: Post in #dev-help Slack channel
- Product: DM Product Owner
- Urgent: Call/text developer directly

**For Bugs:**
- Critical (blocks demo): Immediate fix, notify stakeholders
- High (impacts workflow): Fix within 24 hours
- Medium/Low: Add to backlog, prioritize in next sprint

**For Scope Changes:**
- Minor (< 1 day effort): Developer discretion
- Major (> 1 day effort): Discuss with Product Owner first
- Significant (changes sprint goal): Schedule emergency meeting

---

**End of Strategy Document**

**Status:** ‚úÖ Ready for Stakeholder Review
**Next Update:** After Sprint 1 (2 weeks from tomorrow)
**Owner:** Development Team (Solo Dev + AI Agents)
**Approvers:** Product Owner, CTO, CEO
